{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "36322c65-7fcb-4a41-994c-efb010fc9739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1e73ec9-144d-4ac1-96db-2df9d97f2698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Unzip the ZIP files\n",
    "zip_filenames = ['Dengue-4-sequences.zip', 'Ebola-sequences.zip', 'SARS-CoV-2-sequences.zip', 'hepatitis-C-3a-sequences.zip', 'influenza-A-sequences.zip', 'mers-sequences.zip']\n",
    "\n",
    "for zip_filename in zip_filenames:\n",
    "    with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "\n",
    "fasta_filenames = [filename[:-4] for filename in zip_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f23a6942-3f0b-4641-8d74-d960635e1cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file Dengue-4-sequences has 3587 sequences.\n",
      "The file Ebola-sequences has 4001 sequences.\n",
      "The file hepatitis-C-3a-sequences has 3331 sequences.\n",
      "The file influenza-A-sequences has 3669 sequences.\n",
      "The file mers-sequences has 1633 sequences.\n",
      "The file SARS-CoV-2-sequences has 4752 sequences.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Apply k-mer encoding\n",
    "def k_mer_enc(filename: str, k: int):\n",
    "    with open(filename + '.fasta', 'r') as file:\n",
    "        seqs = []\n",
    "        seq = \"\"\n",
    "        for line in file.readlines():\n",
    "            if line.startswith('>'):\n",
    "                if len(seq) > 0:\n",
    "                    seqs.append(seq)\n",
    "                    seq = \"\"\n",
    "            else:\n",
    "                seq += line.strip('\\n')\n",
    "        if len(seq) > 0:\n",
    "            seqs.append(seq)\n",
    "\n",
    "        print(f'The file {filename} has {len(seqs)} sequences.')\n",
    "\n",
    "        encodings = []\n",
    "        for seq in seqs:\n",
    "            encoding = []\n",
    "            code = 0\n",
    "            for c in seq:\n",
    "                code *= 4\n",
    "                if c == 'A':\n",
    "                    code += 0\n",
    "                if c == 'C':\n",
    "                    code += 1\n",
    "                if c == 'G':\n",
    "                    code += 2\n",
    "                if c == 'T':\n",
    "                    code += 3\n",
    "                code %= 4 ** k\n",
    "                encoding.append(code)\n",
    "            assert len(seq) == len(encoding), 'Error: Unmatched number of characters!'\n",
    "            encodings.append(encoding)\n",
    "        assert len(seqs) == len(encodings), 'Error: Unmatched number of sequences!'\n",
    "\n",
    "        with open(filename + '.pkl', 'wb') as pkfile:\n",
    "            pickle.dump(encodings, pkfile)\n",
    "\n",
    "filenames = ['Dengue-4-sequences', 'Ebola-sequences', 'hepatitis-C-3a-sequences',\n",
    "             'influenza-A-sequences', 'mers-sequences', 'SARS-CoV-2-sequences']\n",
    "for filename in filenames:\n",
    "    k_mer_enc(filename, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d853fe19-26a3-4597-852b-c17c4144cef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Build the ConvLSTM model\n",
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, kernel_size, num_layers, dropout):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embed = nn.Embedding(input_size, hidden_size)\n",
    "        self.convlstm = nn.LSTM(hidden_size, hidden_size, num_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x, _ = self.convlstm(x)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "39663511-658e-4967-a9e7-1667c090184f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Model training and evaluation\n",
    "class VirusDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.encodings[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dd589810-26c1-4a9a-8b4f-697decf16376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, targets in dataloader:\n",
    "        # Move tensors to the correct device\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "475d1b48-905f-4066-998e-d755beac7844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    truths = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs, labels = batch\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            truths.extend(labels.cpu().numpy())\n",
    "\n",
    "    return predictions, truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "750e53d2-c85a-4222-b01c-899e6c0327fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_true, y_pred_prob, num_classes):\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true, y_pred_prob[:, i], pos_label=i)\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        plt.plot(fpr[i], tpr[i], label=f\"Class {i}\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9185b0b5-917e-474a-b9ea-8e20349ba9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "input_size = 4**4  # k-mer encoding with k=4 gives 256 possible combinations\n",
    "hidden_size = 256\n",
    "output_size = len(fasta_filenames)  # Number of virus classes\n",
    "kernel_size = 3\n",
    "num_layers = 3\n",
    "dropout = 0.5\n",
    "num_epochs = 25\n",
    "batch_size = 32\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "76779cf1-57bb-4e4c-9e44-2ae6dc67278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "encodings = []\n",
    "labels = []\n",
    "for label, fasta_filename in enumerate(fasta_filenames):\n",
    "    with open(fasta_filename + '.pkl', 'rb') as pkfile:\n",
    "        file_encodings = pickle.load(pkfile)\n",
    "        encodings.extend([np.array(enc) for enc in file_encodings])  # Convert nested lists to NumPy arrays\n",
    "        labels.extend([label] * len(file_encodings))\n",
    "\n",
    "encodings = np.array(encodings, dtype=object)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Find the maximum sequence length\n",
    "max_seq_len = max([enc.shape[0] for enc in encodings])\n",
    "\n",
    "# Pad encodings with zeros to create tensors\n",
    "encodings_padded = []\n",
    "for enc in encodings:\n",
    "    pad_rows = max_seq_len - enc.shape[0]\n",
    "    enc_padded = np.pad(enc, (0, pad_rows), mode='constant', constant_values=0)\n",
    "    encodings_padded.append(enc_padded)\n",
    "\n",
    "encodings = np.stack(encodings_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "972f5c4a-0da6-4242-a634-9351a8032ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Split the data into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(encodings, labels, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "train_dataset = VirusDataset(X_train, y_train)\n",
    "val_dataset = VirusDataset(X_val, y_val)\n",
    "test_dataset = VirusDataset(X_test, y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4da8bd01-ab70-4f66-975f-d2f3ed6865b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create an EarlyStopping class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif self.best_loss - val_loss > self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            print(f\"Early stopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "acd4350d-8ab8-41c1-bdda-eefff3a70628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ConvLSTM(input_size, hidden_size, output_size, kernel_size, num_layers, dropout).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "963f4de6-833e-4838-9453-92cf5613dc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True, threshold=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d0027988-5391-4bc3-9155-8a795f3ff452",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 7.94 GiB (GPU 0; 23.69 GiB total capacity; 21.52 GiB already allocated; 420.69 MiB free; 22.01 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [63]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 5\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     _, y_val_pred \u001b[38;5;241m=\u001b[39m evaluate(model, val_dataloader)\n\u001b[1;32m      7\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m criterion(torch\u001b[38;5;241m.\u001b[39mtensor(y_val_pred), torch\u001b[38;5;241m.\u001b[39mtensor(y_val))\u001b[38;5;241m.\u001b[39mitem()\n",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataloader, criterion, optimizer)\u001b[0m\n\u001b[1;32m      8\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36mConvLSTM.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed(x)\n\u001b[0;32m---> 18\u001b[0m     x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n\u001b[1;32m     20\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(x)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:761\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 761\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    764\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    765\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 7.94 GiB (GPU 0; 23.69 GiB total capacity; 21.52 GiB already allocated; 420.69 MiB free; 22.01 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# Step 3: # Train model Use the EarlyStopping class in the training loop\n",
    "early_stopping = EarlyStopping(patience=8, min_delta=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model, train_dataloader, criterion, optimizer)\n",
    "    _, y_val_pred = evaluate(model, val_dataloader)\n",
    "    val_loss = criterion(torch.tensor(y_val_pred), torch.tensor(y_val)).item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "    scheduler.step(train_loss)\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.stop:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c0e7cc-6120-421a-b854-3f6d7adfa7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"virus_classification_model_0.001.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f732283-9c46-4f51-9f6a-a9584f58e12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "y_pred, y_true = evaluate(model, test_dataloader)\n",
    "\n",
    "# Metrics\n",
    "test_loss = criterion(torch.tensor(y_pred), torch.tensor(y_true)).item()\n",
    "test_acc = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='macro')\n",
    "recall = recall_score(y_true, y_pred, average='macro')\n",
    "specificity = recall_score(y_true, y_pred, average='macro', pos_label=0)\n",
    "f_score = f1_score(y_true, y_pred, average='macro')\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Acc: {test_acc:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "print(f\"F-score: {f_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07e0dd6-9bf0-458a-94ba-833379ec431e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC scores\n",
    "y_pred_prob = torch.softmax(torch.tensor(y_pred), dim=1).numpy()\n",
    "for i in range(output_size):\n",
    "    auc = roc_auc_score(np.array(y_true) == i, y_pred_prob[:, i])\n",
    "    print(f\"AUC score (Class {i} vs. Other Classes): {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e024db-d5f0-4f8a-9dd7-5d7ed82ecd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283178c3-52aa-46b5-b85f-6d10e3998a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "plot_roc_curve(y_true, y_pred_prob, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e661fb46-9264-4475-aec1-5234cda2715c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(cm, labels):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(cm, fasta_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71859c5-53e9-4d13-a834-1eb3e81ab1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(output_size):\n",
    "    auc = roc_auc_score(np.array(y_true) == i, y_pred_prob[:, i])\n",
    "    print(f\"AUC score (Class {i} vs. Other Classes): {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fe4b32a9-b358-4358-a3f2-8810f865ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c78a7f-c224-4944-8340-54d80601fe74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
